{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87419e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy import linalg\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import eig, eigh\n",
    "from scipy.fft import fft\n",
    "from scipy.special import eval_gegenbauer, sph_harm\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#import scaleogram as scg\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import warnings\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from visuals import *\n",
    "from my_lib import *\n",
    "from SSA_lib import SSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76fff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82a1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CartesianToSpherical(point):\n",
    "    r = np.sqrt(sum(point ** 2))\n",
    "    n = len(point)\n",
    "    phi = np.zeros(n - 1)\n",
    "    \n",
    "    for i in range(n - 2):\n",
    "        phi[i] = np.arccos(point[i] / np.sqrt(sum(point[i:] ** 2)))\n",
    "        \n",
    "    if point[-1] >= 0:\n",
    "        phi[n - 2] = np.arccos(point[n - 2] / np.sqrt(point[n - 1] ** 2 + point[n - 2] ** 2))\n",
    "    else:\n",
    "        phi[n - 2] = 2 * np.pi - np.arccos(point[n - 2] / np.sqrt(point[n - 1] ** 2 + point[n - 2] ** 2))\n",
    "        \n",
    "    return np.hstack((phi, r))\n",
    "\n",
    "\n",
    "def TrajectoryToSpherical(tr):\n",
    "    tr_spherical = np.zeros(tr.shape)\n",
    "    for i, point in enumerate(tr):\n",
    "        tr_spherical[i] = CartesianToSpherical(point)\n",
    "    return tr_spherical\n",
    "\n",
    "\n",
    "def SphericalToCartesian(point):\n",
    "    phi, r = point[:-1], point[-1]\n",
    "    n = len(point)\n",
    "    x = np.zeros(n) \n",
    "    cur = r\n",
    "    \n",
    "    for i in range(n - 1):\n",
    "        x[i] = cur * np.cos(phi[i])\n",
    "        cur *= np.sin(phi[i])\n",
    "\n",
    "    x[n - 1] = cur\n",
    "    return x\n",
    "    \n",
    "def TrajectoryToCartesian(tr):\n",
    "    tr_cartesian = np.zeros(tr.shape)\n",
    "    for i, point in enumerate(tr):\n",
    "        tr_cartesian[i] = SphericalToCartesian(point)\n",
    "    return tr_cartesian\n",
    "\n",
    "def HankelMatrix(X, L):  \n",
    "    N = X.shape[0]\n",
    "    return scipy.linalg.hankel(X[ : N - L + 1], X[N - L : N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a49a2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import lpmv, gamma, hyp2f1\n",
    "\n",
    "def k_c_l_L(k,l,L):\n",
    "    \"\"\" Normalizing  constant \"\"\"\n",
    "#     print('k,l,L', k,l,L)\n",
    "#     print('L + l + k - 2', L + l + k - 2)\n",
    "#     print('L - l', L - l)\n",
    "    ans = ((2*L + k - 1)/ 2) \\\n",
    "    * math.factorial(L + l + k - 2)/math.factorial(L - l)\n",
    "    ans = ans**.5\n",
    "    return ans\n",
    "\n",
    "def P_neg_mu_nu(neg_mu,nu,x):\n",
    "    \"\"\"The associated Legendre function\"\"\"\n",
    "    mu = - neg_mu\n",
    "    return (1/gamma(1+mu)) * (((1-x)/(1+x))**(mu/2)) * (hyp2f1(-nu,nu+1,1+mu,(1-x)/2))\n",
    "\n",
    "def hat_k_P_L(k, l, L, alpha):\n",
    "    hat_k_P_L_ans = k_c_l_L(k,l,L)\n",
    "    hat_k_P_L_ans *= (np.sin(alpha)) ** (-(k-2)/2)\n",
    "    hat_k_P_L_ans *= P_neg_mu_nu(\n",
    "        -(l + ((k-2)/2)),\n",
    "        +(L + ((k-2)/2)),\n",
    "        np.cos(alpha)\n",
    "    )\n",
    "    return hat_k_P_L_ans\n",
    "\n",
    "def high_order_sph_harm(l, theta, phi):\n",
    "    k = len(l)\n",
    "    high_order_sph_harm_array = np.exp(1j*l[0]*phi).reshape((-1,1))\n",
    "    \n",
    "    for i in range(k-1):\n",
    "        high_order_sph_harm_array *= np.nan_to_num(\n",
    "            hat_k_P_L(\n",
    "                int(2+i),\n",
    "                np.abs(l[i]),\n",
    "                l[i+1],\n",
    "                theta[:,i]) * (1/((2*np.pi)**.5)),\n",
    "            nan = 0.0).reshape((-1,1))\n",
    "        \n",
    "    if l[0] > 0:\n",
    "        return (-1)**l[0] * high_order_sph_harm_array\n",
    "    else:\n",
    "        return high_order_sph_harm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636d5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAND_RESULT = {}\n",
    "models_dict = {}\n",
    "history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21d776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3b692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f7bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40621bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_motion = 'jog_9'\n",
    "dir_list = ['wlk_8', 'jog_9', 'ups_12']\n",
    "sub_num = 1\n",
    "min_dim = 3\n",
    "\n",
    "\n",
    "# обучили PCA для конкретного движения\n",
    "df = pd.read_csv(f'./data/A_DeviceMotion_data/{class_motion}/sub_{sub_num}.csv')\n",
    "x_1 = df[['gravity.x', 'gravity.y','gravity.z']].to_numpy()*9.8\n",
    "x_2 = df[['userAcceleration.x', 'userAcceleration.y','userAcceleration.z']].to_numpy()*9.8\n",
    "x = x_1+x_2\n",
    "x = np.sum(x**2,axis = 1)**.5 - 9.8\n",
    "pivot = int(1/3 * len(x))\n",
    "\n",
    "X = HankelMatrix(x[:pivot], 100)\n",
    "pca_ = PCA(n_components = min_dim)\n",
    "pca_.fit(X)\n",
    "models_dict[f'PCA_{class_motion}_dim{min_dim}'] = pca_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c450b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_collection = []\n",
    "y_collection = []\n",
    "\n",
    "for i, motion in enumerate(dir_list):\n",
    "    df = pd.read_csv(f'./data/A_DeviceMotion_data/{motion}/sub_{sub_num}.csv')\n",
    "    x_1 = df[['gravity.x', 'gravity.y','gravity.z']].to_numpy()*9.8\n",
    "    x_2 = df[['userAcceleration.x', 'userAcceleration.y','userAcceleration.z']].to_numpy()*9.8\n",
    "    x = x_1+x_2\n",
    "    x = np.sum(x**2,axis = 1)**.5 - 9.8\n",
    "    pivot = int(2/3 * len(x))\n",
    "    \n",
    "    motion_X = HankelMatrix(x[:pivot], 100)\n",
    "    motion_X = models_dict['PCA_'+str(class_motion)+'_dim'+str(min_dim)].transform(motion_X)\n",
    "    for subsample_size in range(0,int(motion_X.shape[0]-300),25):\n",
    "        X_collection.append(motion_X[subsample_size:subsample_size+300])\n",
    "        if motion == class_motion:\n",
    "            y_collection.append(1)\n",
    "        else:\n",
    "            y_collection.append(0)\n",
    "        \n",
    "y_collection = np.array(y_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e7ea2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7800458356749a0905017e5247a9cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sp_harm(phi, theta, N = 10):\n",
    "    sph_harm_discret_basis = []\n",
    "\n",
    "    for n in range(N):\n",
    "        for m in range(-n,n+1):\n",
    "            if m >= 0:\n",
    "                sph_harm_discret_basis.append(\n",
    "                    np.real(high_order_sph_harm([m,n],theta, phi))\n",
    "                )\n",
    "            elif m < 0:\n",
    "                sph_harm_discret_basis.append(\n",
    "                    np.imag(high_order_sph_harm([m,n],theta, phi))\n",
    "                )\n",
    "\n",
    "    return np.array(sph_harm_discret_basis).T\n",
    "\n",
    "phi = np.linspace(0, 2*np.pi, 100)\n",
    "theta = np.linspace(0, np.pi, 100)\n",
    "phi, theta = np.meshgrid(phi, theta)\n",
    "phi = phi.reshape(-1,1)\n",
    "theta = theta.reshape(-1,1)\n",
    "SH_basis_init = create_sp_harm(phi, theta, N = 10)[0]\n",
    "\n",
    "Y_0 = np.zeros((len(theta),1))\n",
    "\n",
    "w_description = []\n",
    "\n",
    "for i in tqdm(np.arange(0,len(X_collection))):\n",
    "\n",
    "    Y_1 = np.ones((X_collection[i].shape[0],1))\n",
    "    step_X_sp = TrajectoryToSpherical(X_collection[i])[:,:-1]\n",
    "    step_Y_full = np.concatenate((Y_0, Y_1), axis = 0)\n",
    "\n",
    "    SH_basis_data = create_sp_harm(step_X_sp[:,1].reshape((-1,1)),\n",
    "                                   step_X_sp[:,0].reshape((-1,1)), \n",
    "                                   N = 10)[0]\n",
    "\n",
    "    SH_basis_full = np.concatenate((SH_basis_init, SH_basis_data), axis = 0)\n",
    "\n",
    "    clf = LogisticRegression(penalty = 'elasticnet',\n",
    "                             l1_ratio = 0.5,\n",
    "                             random_state = 42,\n",
    "                             fit_intercept = False,\n",
    "                             solver='saga',\n",
    "                             class_weight = 'balanced'\n",
    "                             \n",
    "                            )\n",
    "    clf.fit(SH_basis_full, step_Y_full)\n",
    "\n",
    "    w_description.append(clf.coef_[0])\n",
    "        \n",
    "w_description = np.array(w_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86a1aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf').fit(w_description, y_collection)\n",
    "models_dict[f'SVM_{class_motion}_dim{min_dim}'] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f244de73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA_ups_12_dim3': PCA(n_components=3),\n",
       " 'SVM_ups_12_dim3': SVC(),\n",
       " 'PCA_wlk_8_dim3': PCA(n_components=3),\n",
       " 'SVM_wlk_8_dim3': SVC(),\n",
       " 'PCA_jog_9_dim3': PCA(n_components=3),\n",
       " 'SVM_jog_9_dim3': SVC()}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82954886",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_collection_test = []\n",
    "y_collection_test = []\n",
    "sub_num = 1\n",
    "for i, motion in enumerate(dir_list):\n",
    "    df = pd.read_csv(f'./data/A_DeviceMotion_data/{motion}/sub_{sub_num}.csv')\n",
    "    x_1 = df[['gravity.x', 'gravity.y','gravity.z']].to_numpy()*9.8\n",
    "    x_2 = df[['userAcceleration.x', 'userAcceleration.y','userAcceleration.z']].to_numpy()*9.8\n",
    "    x = x_1+x_2\n",
    "    x = np.sum(x**2,axis = 1)**.5 - 9.8\n",
    "    pivot = int(2/3 * len(x))\n",
    "    \n",
    "    motion_X = HankelMatrix(x[pivot:], 100)\n",
    "    motion_X = models_dict['PCA_'+str(class_motion)+'_dim'+str(min_dim)].transform(motion_X)\n",
    "    for subsample_size in range(0,int(motion_X.shape[0]-300),25):\n",
    "        X_collection_test.append(motion_X[subsample_size:subsample_size+300])\n",
    "        if motion == class_motion:\n",
    "            y_collection_test.append(1)\n",
    "        else:\n",
    "            y_collection_test.append(0)\n",
    "        \n",
    "y_collection_test = np.array(y_collection_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1af21072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70515692b32415399276aaa6e50bd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_description_test = []\n",
    "\n",
    "for i in tqdm(np.arange(0,len(X_collection_test))):\n",
    "\n",
    "    Y_1 = np.ones((X_collection[i].shape[0],1))\n",
    "    step_X_sp = TrajectoryToSpherical(X_collection_test[i])[:,:-1]\n",
    "    step_Y_full = np.concatenate((Y_0, Y_1), axis = 0)\n",
    "\n",
    "    SH_basis_data = create_sp_harm(step_X_sp[:,1].reshape((-1,1)),\n",
    "                                   step_X_sp[:,0].reshape((-1,1)), \n",
    "                                   N = 10)[0]\n",
    "\n",
    "    SH_basis_full = np.concatenate((SH_basis_init, SH_basis_data), axis = 0)\n",
    "\n",
    "    clf = LogisticRegression(penalty = 'elasticnet',\n",
    "                             l1_ratio = 0.5,\n",
    "                             random_state = 42,\n",
    "                             fit_intercept = False,\n",
    "                             solver='saga',\n",
    "                             class_weight = 'balanced'\n",
    "                             \n",
    "                            )\n",
    "    clf.fit(SH_basis_full, step_Y_full)\n",
    "\n",
    "    w_description_test.append(clf.coef_[0])\n",
    "        \n",
    "w_description_test = np.array(w_description_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69ce3ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "clf_pred = models_dict[f'SVM_{class_motion}_dim{min_dim}'].predict(w_description)\n",
    "print(f1_score(y_collection, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "065c8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pred = models_dict[f'SVM_{class_motion}_dim{min_dim}'].predict(w_description_test)\n",
    "f1_score(y_collection_test, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17320fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f26dd9a6ec4922aee64eb7b06a10d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_description_subs = []\n",
    "y_collection_subs = []\n",
    "\n",
    "for sub_num in tqdm([1,9,22]):\n",
    "\n",
    "    X_collection_sub = []\n",
    "    y_collection_sub = []\n",
    "    \n",
    "\n",
    "    for i, motion in enumerate(dir_list):\n",
    "        df = pd.read_csv(f'./data/A_DeviceMotion_data/{motion}/sub_{sub_num}.csv')\n",
    "        x_1 = df[['gravity.x', 'gravity.y','gravity.z']].to_numpy()*9.8\n",
    "        x_2 = df[['userAcceleration.x', 'userAcceleration.y','userAcceleration.z']].to_numpy()*9.8\n",
    "        x = x_1+x_2\n",
    "        x = np.sum(x**2,axis = 1)**.5 - 9.8\n",
    "\n",
    "        motion_X = HankelMatrix(x[:1000], 100)\n",
    "        motion_X = models_dict['PCA_'+str(class_motion)+'_dim'+str(min_dim)].transform(motion_X)\n",
    "#         fig = plt.figure(figsize=(5, 5))\n",
    "#         ax = fig.add_subplot(111,projection='3d')\n",
    "#         ax.plot(motion_X[:1000,0], motion_X[:1000,1], motion_X[:1000,2], lw = 3)\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "        for subsample_size in range(0,int(motion_X.shape[0]-400),25):\n",
    "            X_collection_sub.append(motion_X[subsample_size:subsample_size+400])\n",
    "            if motion == class_motion:\n",
    "                y_collection_sub.append(1)\n",
    "            else:\n",
    "                y_collection_sub.append(0)\n",
    "        \n",
    "        \n",
    "\n",
    "    y_collection_sub = np.array(y_collection_sub)\n",
    "    w_description_sub = []\n",
    "\n",
    "    for i in tqdm(np.arange(0,len(X_collection_sub)), leave = False):\n",
    "\n",
    "        Y_1 = np.ones((X_collection_sub[i].shape[0],1))\n",
    "        step_X_sp = TrajectoryToSpherical(X_collection_sub[i])[:,:-1]\n",
    "        step_Y_full = np.concatenate((Y_0, Y_1), axis = 0)\n",
    "\n",
    "        SH_basis_data = create_sp_harm(step_X_sp[:,1].reshape((-1,1)),\n",
    "                                       step_X_sp[:,0].reshape((-1,1)), \n",
    "                                       N = 10)[0]\n",
    "\n",
    "        SH_basis_full = np.concatenate((SH_basis_init, SH_basis_data), axis = 0)\n",
    "\n",
    "        clf = LogisticRegression(penalty = 'elasticnet',\n",
    "                                 l1_ratio = 0.5,\n",
    "                                 random_state = 42,\n",
    "                                 fit_intercept = False,\n",
    "                                 solver='saga',\n",
    "                                 class_weight = 'balanced'\n",
    "\n",
    "                                )\n",
    "        clf.fit(SH_basis_full, step_Y_full)\n",
    "\n",
    "        w_description_sub.append(clf.coef_[0])\n",
    "\n",
    "    w_description_sub = np.array(w_description_sub)\n",
    "    \n",
    "    w_description_subs.append(w_description_sub)\n",
    "    y_collection_subs.append(y_collection_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16b2f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.8947368421052632\n",
      "\n",
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "ans = 0\n",
    "for i in range(len(w_description_subs)):\n",
    "    clf_pred = models_dict[f'SVM_{class_motion}_dim{min_dim}'].predict(w_description_subs[i])\n",
    "    print(f1_score(y_collection_subs[i], clf_pred))\n",
    "    history[f'{class_motion}_{i}'] = f1_score(y_collection_subs[i], clf_pred)\n",
    "    ans += f1_score(y_collection_subs[i], clf_pred)\n",
    "ans /= len(w_description_subs)\n",
    "print()\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e46a8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAND_RESULT[class_motion] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb148c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.86,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50fdff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ups_12_0': 0.8648648648648648,\n",
       " 'ups_12_1': 0.9500000000000001,\n",
       " 'ups_12_2': 1.0,\n",
       " 'wlk_8_0': 1.0,\n",
       " 'wlk_8_1': 1.0,\n",
       " 'wlk_8_2': 0.8,\n",
       " 'jog_9_0': 1.0,\n",
       " 'jog_9_1': 1.0,\n",
       " 'jog_9_2': 0.8947368421052632}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d63f3d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ups_12': 0.9382882882882884,\n",
       " 'wlk_8': 0.9333333333333332,\n",
       " 'jog_9': 0.9649122807017544}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAND_RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.9215686274509803, 0.8333333333333334, 0.9382882882882884])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([0.9215686274509803, 0.8333333333333334, 0.9382882882882884])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a93ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
